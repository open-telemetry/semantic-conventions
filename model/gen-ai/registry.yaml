groups:
  - id: registry.gen_ai
    type: attribute_group
    display_name: GenAI Attributes
    brief: >
      This document defines the attributes used to describe telemetry in the context of Generative Artificial Intelligence (GenAI) Models requests and responses.
    attributes:
      - id: gen_ai.system
        stability: experimental
        type:
          members:
            - id: openai
              stability: experimental
              value: "openai"
              brief: 'OpenAI'
            - id: vertex_ai
              stability: experimental
              value: "vertex_ai"
              brief: 'Vertex AI'
            - id: anthropic
              stability: experimental
              value: "anthropic"
              brief: 'Anthropic'
            - id: cohere
              stability: experimental
              value: "cohere"
              brief: 'Cohere'
            - id: az.ai.inference
              stability: experimental
              value: "az.ai.inference"
              brief: 'Azure AI Inference'
            - id: ibm.watsonx.ai
              stability: experimental
              value: "ibm.watsonx.ai"
              brief: 'IBM Watsonx AI'
            - id: aws.bedrock
              stability: experimental
              value: "aws.bedrock"
              brief: 'AWS Bedrock'
        brief: The Generative AI product as identified by the client or server instrumentation.
        note: |
          The `gen_ai.system` describes a family of GenAI models with specific model identified
          by `gen_ai.request.model` and `gen_ai.response.model` attributes.

          The actual GenAI product may differ from the one identified by the client.
          For example, when using OpenAI client libraries to communicate with Mistral, the `gen_ai.system`
          is set to `openai` based on the instrumentation's best knowledge.

          For custom model, a custom friendly name SHOULD be used.
          If none of these options apply, the `gen_ai.system` SHOULD be set to `_OTHER`.
        examples: 'openai'
      - id: gen_ai.request.model
        stability: experimental
        type: string
        brief: The name of the GenAI model a request is being made to.
        examples: 'gpt-4'
      - id: gen_ai.request.max_tokens
        stability: experimental
        type: int
        brief: The maximum number of tokens the model generates for a request.
        examples: [100]
      - id: gen_ai.request.temperature
        stability: experimental
        type: double
        brief: The temperature setting for the GenAI request.
        examples: [0.0]
      - id: gen_ai.request.top_p
        stability: experimental
        type: double
        brief: The top_p sampling setting for the GenAI request.
        examples: [1.0]
      - id: gen_ai.request.top_k
        stability: experimental
        type: double
        brief: The top_k sampling setting for the GenAI request.
        examples: [1.0]
      - id: gen_ai.request.stop_sequences
        stability: experimental
        type: string[]
        brief: List of sequences that the model will use to stop generating further tokens.
        examples:
          - [forest, lived]
      - id: gen_ai.request.frequency_penalty
        stability: experimental
        type: double
        brief: The frequency penalty setting for the GenAI request.
        examples: [0.1]
      - id: gen_ai.request.presence_penalty
        stability: experimental
        type: double
        brief: The presence penalty setting for the GenAI request.
        examples: [0.1]
      - id: gen_ai.response.id
        stability: experimental
        type: string
        brief: The unique identifier for the completion.
        examples: ['chatcmpl-123']
      - id: gen_ai.response.model
        stability: experimental
        type: string
        brief: The name of the model that generated the response.
        examples: ['gpt-4-0613']
      - id: gen_ai.response.finish_reasons
        stability: experimental
        type: string[]
        brief: Array of reasons the model stopped generating tokens, corresponding to each generation received.
        examples:
          - [stop]
          - [stop, length]
      - id: gen_ai.usage.input_tokens
        stability: experimental
        type: int
        brief: The number of tokens used in the GenAI input (prompt).
        examples: [100]
      - id: gen_ai.usage.output_tokens
        stability: experimental
        type: int
        brief: The number of tokens used in the GenAI response (completion).
        examples: [180]
      - id: gen_ai.token.type
        stability: experimental
        type:
          members:
            - id: input
              stability: experimental
              value: "input"
              brief: 'Input tokens (prompt, input, etc.)'
            - id: completion
              stability: experimental
              value: "output"
              brief: 'Output tokens (completion, response, etc.)'
        brief: The type of token being counted.
        examples: ['input', 'output']
      - id: gen_ai.operation.name
        stability: experimental
        type:
          members:
            - id: chat
              value: "chat"
              brief: 'Chat completion operation such as [OpenAI Chat API](https://platform.openai.com/docs/api-reference/chat)'
              stability: experimental
            - id: text_completion
              value: "text_completion"
              brief: 'Text completions operation such as [OpenAI Completions API (Legacy)](https://platform.openai.com/docs/api-reference/completions)'
              stability: experimental
        brief: The name of the operation being performed.
        note: >
          If one of the predefined values applies, but specific system uses a different name it's RECOMMENDED to document it in the semantic
          conventions for specific GenAI system and use system-specific name in the instrumentation.
          If a different name is not documented, instrumentation libraries SHOULD use applicable predefined value.
  - id: registry.gen_ai.openai
    type: attribute_group
    display_name: OpenAI Attributes
    brief: >
      Thie group defines attributes for OpenAI.
    attributes:
      - id: gen_ai.openai.request.seed
        stability: experimental
        type: int
        brief: Requests with same seed value more likely to return same result.
        examples: [100]
      - id: gen_ai.openai.request.response_format
        stability: experimental
        type:
          members:
            - id: text
              value: "text"
              brief: 'Text response format'
              stability: experimental
            - id: json_object
              value: "json_object"
              brief: 'JSON object response format'
              stability: experimental
            - id: json_schema
              value: "json_schema"
              brief: 'JSON schema response format'
              stability: experimental
        brief: The response format that is requested.
        examples: ['json']
      - id: gen_ai.openai.request.service_tier
        stability: experimental
        type:
          members:
            - id: auto
              value: "auto"
              brief: The system will utilize scale tier credits until they are exhausted.
              stability: experimental
            - id: default
              value: "default"
              brief: The system will utilize the default scale tier.
              stability: experimental
        brief: The service tier requested. May be a specific tier, default, or auto.
        examples: ['auto', 'default']
      - id: gen_ai.openai.response.service_tier
        stability: experimental
        type: string
        brief: The service tier used for the response.
        examples: ['scale', 'default']
      - id: gen_ai.openai.response.system_fingerprint
        stability: experimental
        type: string
        brief: A fingerprint to track any eventual change in the Generative AI environment.
        examples: ["fp_44709d6fcb"]
