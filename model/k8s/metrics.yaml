groups:
  # k8s.pod.* metrics
  - id: metric.k8s.pod.uptime
    type: metric
    metric_name: k8s.pod.uptime
    stability: experimental
    brief: "The time the Pod has been running"
    note: |
      Instrumentations SHOULD use a gauge with type `double` and measure uptime in seconds as a floating point number with the highest precision available.
      The actual accuracy would depend on the instrumentation and operating system.
    instrument: gauge
    unit: "s"
  # k8s.pod.cpu.* metrics
  - id: metric.k8s.pod.cpu.time
    type: metric
    metric_name: k8s.pod.cpu.time
    stability: experimental
    brief: "Total CPU time consumed"
    note: >
      Total CPU time consumed by the specific Pod on all available CPU cores
    instrument: counter
    unit: "s"
  - id: metric.k8s.pod.cpu.usage
    type: metric
    metric_name: k8s.pod.cpu.usage
    stability: experimental
    brief: "Pod's CPU usage, measured in cpus. Range from 0 to the number of allocatable CPUs"
    note: >
      CPU usage of the specific Pod on all available CPU cores, averaged over the sample window
    instrument: gauge
    unit: "{cpu}"

  # k8s.pod.memory.* metrics
  - id: metric.k8s.pod.memory.usage
    type: metric
    metric_name: k8s.pod.memory.usage
    stability: experimental
    brief: "Memory usage of the Pod"
    note: >
      Total memory usage of the Pod
    instrument: gauge
    unit: "By"

  # k8s.pod.network.* metrics
  - id: metric.k8s.pod.network.io
    type: metric
    metric_name: k8s.pod.network.io
    stability: experimental
    brief: "Network bytes for the Pod"
    instrument: counter
    unit: "By"
    attributes:
      - ref: network.interface.name
      - ref: network.io.direction
  - id: metric.k8s.pod.network.errors
    type: metric
    metric_name: k8s.pod.network.errors
    stability: experimental
    brief: "Pod network errors"
    instrument: counter
    unit: "{error}"
    attributes:
      - ref: network.interface.name
      - ref: network.io.direction

  # k8s.node.* metrics
  - id: metric.k8s.node.uptime
    type: metric
    metric_name: k8s.node.uptime
    stability: experimental
    brief: "The time the Node has been running"
    note: |
      Instrumentations SHOULD use a gauge with type `double` and measure uptime in seconds as a floating point number with the highest precision available.
      The actual accuracy would depend on the instrumentation and operating system.
    instrument: gauge
    unit: "s"
  # k8s.node.cpu.* metrics
  - id: metric.k8s.node.cpu.time
    type: metric
    metric_name: k8s.node.cpu.time
    stability: experimental
    brief: "Total CPU time consumed"
    note: >
      Total CPU time consumed by the specific Node on all available CPU cores
    instrument: counter
    unit: "s"
  - id: metric.k8s.node.cpu.usage
    type: metric
    metric_name: k8s.node.cpu.usage
    stability: experimental
    brief: "Node's CPU usage, measured in cpus. Range from 0 to the number of allocatable CPUs"
    note: >
      CPU usage of the specific Node on all available CPU cores, averaged over the sample window
    instrument: gauge
    unit: "{cpu}"

  # k8s.node.memory.* metrics
  - id: metric.k8s.node.memory.usage
    type: metric
    metric_name: k8s.node.memory.usage
    stability: experimental
    brief: "Memory usage of the Node"
    note: >
      Total memory usage of the Node
    instrument: gauge
    unit: "By"

  # k8s.node.network.* metrics
  - id: metric.k8s.node.network.io
    type: metric
    metric_name: k8s.node.network.io
    stability: experimental
    brief: "Network bytes for the Node"
    instrument: counter
    unit: "By"
    attributes:
      - ref: network.interface.name
      - ref: network.io.direction
  - id: metric.k8s.node.network.errors
    type: metric
    metric_name: k8s.node.network.errors
    stability: experimental
    brief: "Node network errors"
    instrument: counter
    unit: "{error}"
    attributes:
      - ref: network.interface.name
      - ref: network.io.direction

  # k8s.deployment.* metrics
  - id: metric.k8s.deployment.desired_pods
    type: metric
    metric_name: k8s.deployment.desired_pods
    stability: experimental
    brief: "Number of desired replica pods in this deployment"
    note: |
      This metric aligns with the `replicas` field of the
      [K8s DeploymentSpec](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#deploymentspec-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.deployment`](../resource/k8s.md#deployment) resource.
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.deployment.available_pods
    type: metric
    metric_name: k8s.deployment.available_pods
    stability: experimental
    brief: "Total number of available replica pods (ready for at least minReadySeconds) targeted by this deployment"
    note: |
      This metric aligns with the `availableReplicas` field of the
      [K8s DeploymentStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#deploymentstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.deployment`](../resource/k8s.md#deployment) resource.
    instrument: updowncounter
    unit: "{pod}"

  # k8s.replicaset.* metrics
  - id: metric.k8s.replicaset.desired_pods
    type: metric
    metric_name: k8s.replicaset.desired_pods
    stability: experimental
    brief: "Number of desired replica pods in this replicaset"
    note: |
      This metric aligns with the `replicas` field of the
      [K8s ReplicaSetSpec](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#replicasetspec-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.replicaset`](../resource/k8s.md#replicaset) resource.
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.replicaset.available_pods
    type: metric
    metric_name: k8s.replicaset.available_pods
    stability: experimental
    brief: "Total number of available replica pods (ready for at least minReadySeconds) targeted by this replicaset"
    note: |
      This metric aligns with the `availableReplicas` field of the
      [K8s ReplicaSetStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#replicasetstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.replicaset`](../resource/k8s.md#replicaset) resource.
    instrument: updowncounter
    unit: "{pod}"

  # k8s.replication_controller.* metrics
  - id: metric.k8s.replication_controller.desired_pods
    type: metric
    metric_name: k8s.replication_controller.desired_pods
    stability: experimental
    brief: "Number of desired replica pods in this replication controller"
    # TODO: Add note for resource correlation once https://github.com/open-telemetry/semantic-conventions/issues/1656 is implemented
    note: |
      This metric aligns with the `replicas` field of the
      [K8s ReplicationControllerSpec](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#replicationcontrollerspec-v1-core)
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.replication_controller.available_pods
    type: metric
    metric_name: k8s.replication_controller.available_pods
    stability: experimental
    brief: "Total number of available replica pods (ready for at least minReadySeconds) targeted by this replication controller"
    # TODO: Add note for resource correlation once https://github.com/open-telemetry/semantic-conventions/issues/1656 is implemented
    note: |
      This metric aligns with the `availableReplicas` field of the
      [K8s ReplicationControllerStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#replicationcontrollerstatus-v1-core)
    instrument: updowncounter
    unit: "{pod}"

  # k8s.statefulset.* metrics
  - id: metric.k8s.statefulset.desired_pods
    type: metric
    metric_name: k8s.statefulset.desired_pods
    stability: experimental
    brief: "Number of desired replica pods in this statefulset"
    note: |
      This metric aligns with the `replicas` field of the
      [K8s StatefulSetSpec](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#statefulsetspec-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.statefulset`](../resource/k8s.md#statefulset) resource.
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.statefulset.ready_pods
    type: metric
    metric_name: k8s.statefulset.ready_pods
    stability: experimental
    brief: "The number of replica pods created for this statefulset with a Ready Condition"
    note: |
      This metric aligns with the `readyReplicas` field of the
      [K8s StatefulSetStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#statefulsetstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.statefulset`](../resource/k8s.md#statefulset) resource.
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.statefulset.current_pods
    type: metric
    metric_name: k8s.statefulset.current_pods
    stability: experimental
    brief: "The number of replica pods created by the statefulset controller from the statefulset version indicated by currentRevision"
    note: |
      This metric aligns with the `currentReplicas` field of the
      [K8s StatefulSetStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#statefulsetstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.statefulset`](../resource/k8s.md#statefulset) resource.
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.statefulset.updated_pods
    type: metric
    metric_name: k8s.statefulset.updated_pods
    stability: experimental
    brief: "Number of replica pods created by the statefulset controller from the statefulset version indicated by updateRevision"
    note: |
      This metric aligns with the `updatedReplicas` field of the
      [K8s StatefulSetStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#statefulsetstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.statefulset`](../resource/k8s.md#statefulset) resource.
    instrument: updowncounter
    unit: "{pod}"

  # k8s.hpa.* metrics
  - id: metric.k8s.hpa.desired_pods
    type: metric
    metric_name: k8s.hpa.desired_pods
    stability: experimental
    brief: "Desired number of replica pods managed by this horizontal pod autoscaler, as last calculated by the autoscaler"
    # TODO: Add note for resource correlation once https://github.com/open-telemetry/semantic-conventions/issues/1656 is implemented
    note: |
      This metric aligns with the `desiredReplicas` field of the
      [K8s HorizontalPodAutoscalerStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#horizontalpodautoscalerstatus-v2-autoscaling)
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.hpa.current_pods
    type: metric
    metric_name: k8s.hpa.current_pods
    stability: experimental
    brief: "Current number of replica pods managed by this horizontal pod autoscaler, as last seen by the autoscaler"
    # TODO: Add note for resource correlation once https://github.com/open-telemetry/semantic-conventions/issues/1656 is implemented
    note: |
      This metric aligns with the `currentReplicas` field of the
      [K8s HorizontalPodAutoscalerStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#horizontalpodautoscalerstatus-v2-autoscaling)
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.hpa.max_pods
    type: metric
    metric_name: k8s.hpa.max_pods
    stability: experimental
    brief: "The upper limit for the number of replica pods to which the autoscaler can scale up"
    # TODO: Add note for resource correlation once https://github.com/open-telemetry/semantic-conventions/issues/1656 is implemented
    note: |
      This metric aligns with the `maxReplicas` field of the
      [K8s HorizontalPodAutoscalerSpec](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#horizontalpodautoscalerspec-v2-autoscaling)
    instrument: updowncounter
    unit: "{pod}"
  - id: metric.k8s.hpa.min_pods
    type: metric
    metric_name: k8s.hpa.min_pods
    stability: experimental
    brief: "The lower limit for the number of replica pods to which the autoscaler can scale down"
    # TODO: Add note for resource correlation once https://github.com/open-telemetry/semantic-conventions/issues/1656 is implemented
    note: |
      This metric aligns with the `minReplicas` field of the
      [K8s HorizontalPodAutoscalerSpec](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#horizontalpodautoscalerspec-v2-autoscaling)
    instrument: updowncounter
    unit: "{pod}"

  # k8s.daemonset.* metrics
  - id: metric.k8s.daemonset.current_scheduled_nodes
    type: metric
    metric_name: k8s.daemonset.current_scheduled_nodes
    stability: experimental
    brief: "Number of nodes that are running at least 1 daemon pod and are supposed to run the daemon pod"
    note: |
      This metric aligns with the `currentNumberScheduled` field of the
      [K8s DaemonSetStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#daemonsetstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.daemonset`](../resource/k8s.md#daemonset) resource.
    instrument: updowncounter
    unit: "{node}"
  - id: metric.k8s.daemonset.desired_scheduled_nodes
    type: metric
    metric_name: k8s.daemonset.desired_scheduled_nodes
    stability: experimental
    brief: "Number of nodes that should be running the daemon pod (including nodes currently running the daemon pod)"
    note: |
      This metric aligns with the `desiredNumberScheduled` field of the
      [K8s DaemonSetStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#daemonsetstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.daemonset`](../resource/k8s.md#daemonset) resource.
    instrument: updowncounter
    unit: "{node}"
  - id: metric.k8s.daemonset.misscheduled_nodes
    type: metric
    metric_name: k8s.daemonset.misscheduled_nodes
    stability: experimental
    brief: "Number of nodes that are running the daemon pod, but are not supposed to run the daemon pod"
    note: |
      This metric aligns with the `numberMisscheduled` field of the
      [K8s DaemonSetStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#daemonsetstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.daemonset`](../resource/k8s.md#daemonset) resource.
    instrument: updowncounter
    unit: "{node}"
  - id: metric.k8s.daemonset.ready_nodes
    type: metric
    metric_name: k8s.daemonset.ready_nodes
    stability: experimental
    brief: "Number of nodes that should be running the daemon pod and have one or more of the daemon pod running and ready"
    note: |
      This metric aligns with the `numberReady` field of the
      [K8s DaemonSetStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#daemonsetstatus-v1-apps).

      This metric SHOULD, at a minimum, be reported against a
      [`k8s.daemonset`](../resource/k8s.md#daemonset) resource.
    instrument: updowncounter
    unit: "{node}"
